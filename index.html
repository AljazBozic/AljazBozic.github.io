<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Aljaž Božič</title>

  <meta name="description" content="The personal website of Aljaž Božič, Ph.D. candidate at TU Munich.">
  <meta name="author" content="Aljaž Božič">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="main_page/stylesheet.css">
  <link rel="icon" type="image/png" href="main_page/images/seal_icon.png">
</head>

<body>
  <table
    style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%; width:63%; vertical-align:middle; text-align: justify;">
                  <p style="text-align:center">
                    <name>Aljaž Božič</name>
                  </p>
                  <p>
                    I am a Ph.D. candidate at <a target="_blank"
                      href="http://niessnerlab.org/members/matthias_niessner/profile.html">Matthias
                      Nießner</a>'s <a target="_blank" target="_blank" href="http://niessnerlab.org/team.html">Visual
                      Computing Group</a>, at the <a target="_blank" href="https://www.tum.de/">Technical University of
                      Munich</a>.
                  </p>
                  <p>
                    I received a Master's Degree in Computer Science from the <a target="_blank"
                      href="https://www.tum.de/">Technical University of Munich</a> and a Bachelor's Degree in
                    Mathematics from the <a target="_blank" href="https://www.uni-lj.si/eng/">University of
                      Ljubljana</a>.
                  </p>
                  <p>
                    I'm interested in computer vision, machine learning and optimization.

                    My research is mostly focused on non-rigid 3D reconstruction, i.e. tracking and reconstructing
                    non-rigidly deforming objects in dynamic environments, with applications in VR/AR, robotics, etc.
                  </p>
                  <p style="text-align:center">
                    <a target="_blank" href="mailto:aljaz.bozic@tum.de">Email</a> &nbsp|&nbsp
                    <a target="_blank" href="https://scholar.google.com/citations?user=92YuESsAAAAJ&hl=en&oi=ao">Google
                      Scholar</a>
                    &nbsp|&nbsp
                    <a target="_blank" href="https://twitter.com/BozicAljaz">Twitter</a> &nbsp|&nbsp
                    <a target="_blank" href="https://github.com/AljazBozic">Github</a>
                  </p>
                </td>
                <td style="padding:2.5%;width:40%;max-width:40%">
                  <a target="_blank" href="main_page/images/AljazBozic.jpg"><img style="width:100%;max-width:100%"
                      alt="profile photo" src="main_page/images/AljazBozic_Circle.jpg" class="hoverZoomLink"></a>
                </td>
              </tr>
            </tbody>
          </table>

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding-left:20px; padding-top:20px; width:100%; vertical-align:middle">
                  <heading>Research</heading>
                </td>
              </tr>
            </tbody>
          </table>

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto; text-align: justify;">
            <tbody>

              <tr onmouseout="ndg_stop()" onmouseover="ndg_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <a target="_blank" href="https://aljazbozic.github.io/neural_deformation_graphs">
                      <div class="two" id="ndg_image" style="opacity: 0;">
                        <video width="100%" height="100%" muted="" autoplay="" loop="">
                          <source src="main_page/images/bozic2021ndg.mp4" type="video/mp4">
                          Your browser does not support the video tag.
                        </video>
                      </div>
                      <img src="main_page/images/bozic2021ndg_before.jpg" width="160">
                    </a>
                  </div>

                  <script type="text/javascript">
                    function ndg_start() {
                      document.getElementById('ndg_image').style.opacity = 1;
                    }
                    function ndg_stop() {
                      document.getElementById('ndg_image').style.opacity = 0;
                    }
                    ndg_stop();
                  </script>
                </td>

                <td style="padding:20px;width:75%;vertical-align:middle">

                  <a target="_blank" href="https://aljazbozic.github.io/neural_deformation_graphs">
                    <papertitle>Neural Deformation Graphs for Globally-consistent Non-rigid Reconstruction</papertitle>
                  </a>
                  <br>

                  <b>Aljaž Božič</b>, Pablo Palafox, Michael Zollhöfer, Justus Thies, Angela Dai, Matthias Nießner<br>
                  <b>ArXiv, 2020</b><br>

                  <a target="_blank" href="https://arxiv.org/abs/2012.01451.pdf">paper</a> |
                  <a target="_blank" href="https://www.youtube.com/watch?v=vyq36eFkdWo">video</a> |
                  <a target="_blank" href="main_page/bibtex/bozic2021ndg.bib" type="text/html">bibtex</a>

                  <p>
                    We introduce Neural Deformation Graphs for globally-consistent deformation tracking and 3D
                    reconstruction of non-rigid objects. Specifically, we implicitly model a deformation graph via a
                    deep neural network and empose per-frame viewpoint consistency as well as inter-frame graph and
                    surface consistency constraints in a self-supervised fashion.
                  </p>

                </td>
              </tr>

              <tr onmouseout="nnrt_stop()" onmouseover="nnrt_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <a target="_blank" href="http://niessnerlab.org/projects/bozic2020nnrt.html">
                      <div class="two" id="nnrt_image" style="opacity: 0;">
                        <img src="main_page/images/bozic2020nnrt.png" width="160">
                      </div>
                      <img src="main_page/images/bozic2020nnrt_before.png" width="160">
                    </a>
                  </div>

                  <script type="text/javascript">
                    function nnrt_start() {
                      document.getElementById('nnrt_image').style.opacity = 1;
                    }
                    function nnrt_stop() {
                      document.getElementById('nnrt_image').style.opacity = 0;
                    }
                    nnrt_stop();
                  </script>
                </td>

                <td style="padding:20px;width:75%;vertical-align:middle">

                  <a target="_blank" href="http://niessnerlab.org/projects/bozic2020nnrt.html">
                    <papertitle>Neural Non-Rigid Tracking</papertitle>
                  </a>
                  <br>

                  <b>Aljaž Božič*</b>, Pablo Palafox*, Michael Zollhöfer, Angela Dai, Justus Thies, Matthias Nießner<br>
                  <b>Proc. Neural Information Processing Systems (NeurIPS), 2020</b><br>

                  <a target="_blank" href="https://arxiv.org/pdf/2006.13240.pdf">paper</a> |
                  <a target="_blank" href="https://github.com/DeformableFriends/NeuralTracking">code</a> |
                  <a target="_blank" href="https://www.youtube.com/watch?v=nqYaxM6Rj8I">video</a> |
                  <a target="_blank" href="main_page/bibtex/bozic2020nnrt.bib" type="text/html">bibtex</a>

                  <p>
                    We introduce a novel, end-to-end learnable, differentiable non-rigid tracker that enables
                    state-of-the-art non-rigid reconstruction. By enabling gradient back-propagation through a non-rigid
                    as-rigid-as-possible optimization solver, we are able to learn correspondences in an end-to-end
                    manner such that they are optimal for the task of non-rigid tracking.
                  </p>

                </td>
              </tr>

              <tr onmouseout="optnrt_stop()" onmouseover="optnrt_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <a target="_blank" href="http://niessnerlab.org/projects/li2020learning.html">
                      <div class="two" id="optnrt_image" style="opacity: 0;">
                        <img src="main_page/images/li2020optnrt.png" width="160">
                      </div>
                      <img src="main_page/images/li2020optnrt_before.png" width="160">
                    </a>
                  </div>

                  <script type="text/javascript">
                    function optnrt_start() {
                      document.getElementById('optnrt_image').style.opacity = 1;
                    }
                    function optnrt_stop() {
                      document.getElementById('optnrt_image').style.opacity = 0;
                    }
                    optnrt_stop();
                  </script>
                </td>

                <td style="padding:20px;width:75%;vertical-align:middle">

                  <a target="_blank" href="http://niessnerlab.org/projects/li2020learning.html">
                    <papertitle>Learning to Optimize Non-Rigid Tracking</papertitle>
                  </a>
                  <br>

                  Yang Li, <b>Aljaž Božič</b>, Tianwei Zhang, Yanli Ji, Tatsuya Harada, Matthias Nießner<br>
                  <b>Conference on Computer Vision and Pattern Recognition (CVPR), 2020 (Oral)</b><br>

                  <a target="_blank" href="https://arxiv.org/pdf/2003.12230.pdf">paper</a> |
                  <a target="_blank" href="https://www.youtube.com/watch?v=oFgMep7xzrU">video</a> |
                  <a target="_blank" href="main_page/bibtex/li2020learning.bib" type="text/html">bibtex</a>

                  <p>
                    We learn the tracking of non-rigid objects by differentiating through the underlying non-rigid
                    solver. Specifically, we propose ConditionNet which learns to generate a problem-specific
                    preconditioner using a large number of training samples from the Gauss-Newton update equation. The
                    learned preconditioner increases PCG’s convergence speed by a significant margin.
                  </p>

                </td>
              </tr>

              <tr onmouseout="deepdeform_stop()" onmouseover="deepdeform_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <a target="_blank" href="http://niessnerlab.org/projects/bozic2020deepdeform.html">
                      <div class="two" id="deepdeform_image" style="opacity: 0;">
                        <video width="100%" height="100%" muted="" autoplay="" loop="">
                          <source src="main_page/images/bozic2020deepdeform.mp4" type="video/mp4">
                          Your browser does not support the video tag.
                        </video>
                      </div>

                      <!-- <div class="two" id="deepdeform_image" style="opacity: 0;">
                        <img src="main_page/images/bozic2020deepdeform.png" width="160">
                      </div> -->
                      <img src="main_page/images/bozic2020deepdeform_before.png" width="160">
                    </a>
                  </div>

                  <script type="text/javascript">
                    function deepdeform_start() {
                      document.getElementById('deepdeform_image').style.opacity = 1;
                    }
                    function deepdeform_stop() {
                      document.getElementById('deepdeform_image').style.opacity = 0;
                    }
                    deepdeform_stop();
                  </script>
                </td>

                <td style="padding:20px;width:75%;vertical-align:middle">

                  <a target="_blank" href="http://niessnerlab.org/projects/bozic2020deepdeform.html">
                    <papertitle>DeepDeform: Learning Non-rigid RGB-D Reconstruction with Semi-supervised Data
                    </papertitle>
                  </a>
                  <br>

                  <b>Aljaž Božič</b>, Michael Zollhöfer, Christian Theobalt, Matthias Nießner<br>
                  <b>Conference on Computer Vision and Pattern Recognition (CVPR), 2020</b><br>

                  <a target="_blank" href="https://arxiv.org/pdf/1912.04302.pdf">paper</a> |
                  <a target="_blank" href="https://www.youtube.com/watch?v=OrHLacCDZVQ">video</a> |
                  <a target="_blank" href="main_page/bibtex/bozic2020deepdeform.bib" type="text/html">bibtex</a>

                  <p>
                    We present a large dataset of 400 scenes, over 390,000 RGB-D frames, and 5,533 densely aligned frame
                    pairs, and introduce a data-driven non-rigid RGB-D reconstruction approach using learned heatmap
                    correspondences, achieving state-of-the-art reconstruction results on a newly established
                    quantitative benchmark.
                  </p>

                </td>
              </tr>

              <tr onmouseout="semanticslam_stop()" onmouseover="semanticslam_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <a href="#">
                      <div class="two" id="semanticslam_image" style="opacity: 0;">
                        <img src="main_page/images/brasch2018semanticslam.png" width="160">
                      </div>
                      <img src="main_page/images/brasch2018semanticslam_before.png" width="160">
                    </a>
                  </div>

                  <script type="text/javascript">
                    function semanticslam_start() {
                      document.getElementById('semanticslam_image').style.opacity = 1;
                    }
                    function semanticslam_stop() {
                      document.getElementById('semanticslam_image').style.opacity = 0;
                    }
                    semanticslam_stop();
                  </script>
                </td>

                <td style="padding:20px;width:75%;vertical-align:middle">

                  <a href="#">
                    <papertitle>Semantic Monocular SLAM for Highly Dynamic Environments</papertitle>
                  </a>
                  <br>

                  <b>Aljaž Božič*</b>, Nikolas Brasch*, Joe Lallemand, Federico Tombari<br>
                  <b>Int. Conference on Intelligent Robots and Systems (IROS), 2018</b><br>

                  <a target="_blank" href="https://ieeexplore.ieee.org/document/8593828">paper</a> |
                  <a target="_blank" href="main_page/bibtex/brasch2018semanticslam.bib" type="text/html">bibtex</a>

                  <p>
                    We propose a semantic monocular SLAM framework designed to deal with highly dynamic environments,
                    combining feature-based and direct approaches to achieve robustness under challenging conditions.
                    Our approach uses deep-learned semantic information extracted from the scene to cope with outliers
                    on dynamic objects.
                  </p>

                </td>
              </tr>

              <tr onmouseout="denseslam_stop()" onmouseover="denseslam_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <a href="#">
                      <div class="two" id="denseslam_image" style="opacity: 0;">
                        <img src="main_page/images/kuschk2017denseslam.png" width="160">
                      </div>
                      <img src="main_page/images/kuschk2017denseslam_before.png" width="160">
                    </a>
                  </div>

                  <script type="text/javascript">
                    function denseslam_start() {
                      document.getElementById('denseslam_image').style.opacity = 1;
                    }
                    function denseslam_stop() {
                      document.getElementById('denseslam_image').style.opacity = 0;
                    }
                    denseslam_stop();
                  </script>
                </td>

                <td style="padding:20px;width:75%;vertical-align:middle">

                  <a href="#">
                    <papertitle>Real-time Variational Stereo Reconstruction with Applications to Large-Scale Dense SLAM
                    </papertitle>
                  </a>
                  <br>

                  Georg Kuschk, <b>Aljaž Božič</b>, Daniel Cremers<br>
                  <b>IEEE Intelligent Vehicles Symposium (IV), 2017</b><br>

                  <a target="_blank" href="https://ieeexplore.ieee.org/document/7995899">paper</a> |
                  <a target="_blank" href="main_page/bibtex/kuschk2017denseslam.bib.bib" type="text/html">bibtex</a>

                  <p>
                    We propose an algorithm for dense and direct large-scale visual SLAM that runs in real-time on a
                    commodity notebook. A fast variational dense 3D reconstruction algorithm was developed which
                    robustly integrates data terms from multiple images. Embedded into a keyframe-based SLAM framework
                    it enables us to densely reconstruct large scenes.
                  </p>

                </td>
              </tr>

            </tbody>
          </table>

          <table style="padding-left:20px; padding-top:20px; width:100%; vertical-align:middle">
            <tbody>
              <tr>
                <td>
                  <heading>Teaching</heading>
                </td>
              </tr>
            </tbody>
          </table>

          <table width="100%" align="center" border="0" cellpadding="20">
            <tbody>
              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src="main_page/images/teaching.png" width="160">
                </td>
                <td width="75%" valign="center" style="line-height:30px;">
                  <a target="_blank"
                    href="https://justusthies.github.io/posts/3D-Scanning-and-Spatial-Learning-WS19-20/">Teaching
                    Assistant, Practical Course: 3D Scanning and Spatial Learning - Winter 2019/20</a>
                  <br>
                  <a target="_blank" href="https://justusthies.github.io/posts/3D-Vision-SS19/">Teaching
                    Assistant, Seminar: 3D Vision Seminar - Summer 2019</a>
                  <br>
                  <a target="_blank" href="https://justusthies.github.io/posts/3D-Vision-WS18-19/">Teaching
                    Assistant, Seminar: 3D Vision Seminar - Winter 2018/19</a>
                  <br>
                  <a target="_blank"
                    href="https://justusthies.github.io/posts/3D-Scanning-and-Motion-Capture-SS18/">Teaching
                    Assistant, Lecture: 3D Scanning & Motion Capture - Summer 2018</a>
                  <br>
                  <a target="_blank"
                    href="https://justusthies.github.io/posts/3D-Scanning-and-Motion-Capture-WS17-18/">Teaching
                    Assistant, Lecture: 3D Scanning & Motion Capture - Winter 2017/18</a>
                </td>
              </tr>
            </tbody>
          </table>

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:0px">
                  <br>
                  <p style="text-align:right;font-size:small;">
                    Source code stolen from <a target="_blank" href="https://jonbarron.info/">Jon Barron</a>.
                  </p>
                </td>
              </tr>
            </tbody>
          </table>
        </td>
      </tr>
  </table>
</body>

</html>